% Section 6: Implications
% Last updated from: v2_2025-01-12.md

\section{Implications for accountable AI systems}
\label{sec:implications}

\foam{} reframes explanation as a contestable record rather than a post-hoc narrative. Instead of producing a single rationale, the system outputs (i) an auditable argument structure (claims, warrants, rebuttals), (ii) explicit perspective configurations, and (iii) sentence-level provenance linking each substantive claim to a checkable source span. This shifts accountability from ``did the explanation sound plausible?'' to ``which premises and evidence does the output depend on, and where can a challenge be lodged?''

Operationally, \foam{} supports contestation at three levels: (1) \textbf{evidence disputes} (a cited sentence does not support the tagged claim; missing counterevidence), (2) \textbf{inferential disputes} (the warrant connecting evidence to conclusion is invalid or incomplete), and (3) \textbf{normative disputes} (the perspective/value configuration is illegitimate or incomplete for the context). Because these objects are explicit, a reviewer can localize disagreement to specific nodes and request revision without reopening the entire output as free-form prose.

Institutionally, the resulting artifact functions as an auditable dossier that can plug into existing governance workflows (internal review, incident response, assurance audits, and post-hoc dispute resolution). The technical contribution is not replacing due process, but supplying the structured, traceable materials that make procedural review feasible at scale.
