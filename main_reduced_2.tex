% FOAM: A Pluralistic Architecture for Explainable and Contestable AI
% FAccT 2026 Submission - REDUCED VERSION

\documentclass[manuscript,screen,review,anonymous]{acmart}

% For submission - remove these lines for camera-ready
\setcopyright{none}
\settopmatter{printfolios=true}

% Fix font expansion issue
\usepackage{lmodern}

% Package imports
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{xspace}

% Custom commands
\newcommand{\foam}{\textsc{FOAM}}
\newcommand{\ie}{i.e.,\xspace}
\newcommand{\eg}{e.g.,\xspace}

% Title and authors
\title{Framework for Openly Augmented Mediation (FOAM): A Pluralistic Architecture for Explainable and Contestable AI}

\author{Devin Gonier}
\affiliation{
  \institution{DebaterHub}
  \country{USA}
}
\email{dgonier@debaterhub.com}

\author{John Hines}
\affiliation{
  \institution{DebaterHub}
  \country{USA}
}
\email{jhines@debaterhub.com}

\author{P. Anand Rao}
\affiliation{
  \institution{University of Mary Washington}
  \department{Center for AI and the Liberal Arts}
  \country{USA}
}
\email{prao@umw.edu}

% Keywords
\keywords{Algorithmic accountability; Contestable AI; Explainable AI (XAI); Multi-agent deliberation; Evidence provenance}

\begin{document}

\begin{abstract}
High-stakes AI systems increasingly mediate access to credit, healthcare, and public benefits, yet affected parties often cannot see why a decision was made or meaningfully contest it. Even post hoc review of chain-of-thought traces from individual models can be incomplete or strategically misleading, thereby limiting accountability. We propose \foam{} (Framework for Openly Augmented Mediation), a pluralistic architecture that treats explanation as a \emph{deliberative process} rather than post-hoc narration. \foam{} instantiates differentiated agents with explicit value commitments, structures their interaction through cross-examination and rebuttal protocols, and outputs not just a recommendation but a \emph{structured record designed to support downstream contestation and review}: claims linked to sentence-level evidence provenance, surviving objections, and explicit points of disagreement. We evaluate \foam{} in evidence-grounded policy debate generation, a domain where arguments must withstand adversarial scrutiny. In a double-blind tournament of 66 cases, \foam{} outperforms human-expert and zero-shot baselines on overall quality (73.5 vs.\ 62.4 vs.\ 46.3) while achieving dramatically higher evidence verifiability (76.2\% case-level full validation vs.\ 8.7\% and 0\%). These results demonstrate that pluralistic deliberation can produce outputs that are simultaneously persuasive \emph{and} auditable, a necessary condition for contestable AI by design.
\end{abstract}

\maketitle

% Include sections - VERSION 2 WITH CUTS
\input{sections/01_introduction}
\input{sections/02_related_work_cc_cuts2}
\input{sections/03_foam_approach_cc_cuts}
\input{sections/04_case_study_cc_cuts2}
\input{sections/05_evaluation_cc_cuts2}
\input{sections/06_implications_cc_cuts2}
\input{sections/07_limitations_cc_cuts2}
\input{sections/08_conclusion}

% === REQUIRED STATEMENTS FOR SUBMISSION ===
% Note: Author Contributions, Acknowledgements, Competing Interests,
% and Positionality Statement should be EXCLUDED for anonymous submission

\clearpage
\section*{Endmatter}

\begin{acks}
This work was supported by the National Science Foundation under SBIR Phase I Grant No. [GRANT\_NUMBER\_HERE].
\end{acks}

\subsection*{Generative AI Usage Statement}
This research investigates the use of large language models (LLMs) within a structured multi-agent deliberation framework. The \foam{} system uses LLMs as pipeline components: Claude 3 Haiku (Anthropic, March 2024) for primary generation, Claude 3.5 Sonnet (Anthropic, June 2024) for refinement phases, and Claude Opus 4 (Anthropic, January 2025) for tournament evaluation, as detailed in Section~\ref{sec:experimental-design}.

Regarding manuscript preparation: the paper text was drafted entirely by human authors. We used Claude 4.5 Opus and ChatGPT 4o solely for grammar checking, \LaTeX{} formatting assistance, and table alignment. No generative AI tools were used for idea generation, argument construction, literature review, experimental design, data analysis, or drafting of substantive prose. All intellectual contributions, claims, interpretations, and conclusions are the product of human judgment. The authors take full responsibility for the accuracy and integrity of this manuscript.

\subsection*{Ethical Considerations}
This work develops AI systems with persuasive capabilities, which raises dual-use concerns. We address these in Section~\ref{sec:limitations} and Section~\ref{sec:implications}, discussing safeguards including transparency requirements, evidence provenance constraints, and the deliberate choice to evaluate in a domain (competitive debate) with established norms for scrutinizing persuasive claims. The evaluation involved no human subjects; all baselines were drawn from publicly available debate materials or generated outputs.

\textbf{Evidence corpus licensing.} \foam{}'s evidence retrieval uses the OpenDebateEvidence corpus~\cite{roush2024opendebate}, released under CC-BY-4.0 for research purposes. Sentence-level provenance preserves attribution to original sources; we do not claim ownership of underlying evidence content.

\subsection*{Adverse Impacts Statement}
Systems that generate persuasive, evidence-grounded arguments could be misused for misinformation, manipulation, or to overwhelm human review capacity. Affected groups include decision-subjects in high-stakes domains and information consumers generally. We mitigate these risks through: (1) provenance requirements that make claims auditable; (2) evaluation in a domain with adversarial scrutiny norms; (3) architectural transparency (the deliberation trace is inspectable). Deployment in sensitive domains should include access controls, logging, human oversight, and institutional review processes.

% Bibliography
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

% Appendix
\input{appendix}

\end{document}
